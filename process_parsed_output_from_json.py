#!/usr/bin/python3
import sys, getopt

# some required input files and defaults

# Expected format of this file is vol:bucket:bucketObjectId.
# This file can be generated by parsing BucketTable
file_all_vol_bucket_object_ids="all_vol_bucket_object_ids.txt";

# Expected format of this file is filename:parentObjectId:objectId.
# This file can be generated by parsing fileTable
file_files_in_a_line_name_parentID_objectId="files_in_a_line_name_parentID_objectId.txt";

# Expected format of this file is dirName:parentObjectId:objectId.
# This file can be generated by parsing directoryTable
file_dirs_in_a_line_name_parentID_objectId="dirs_in_a_line_name_parentID_objectId.txt";

# global maps
all_child_to_parent={};
ft_mappings={};
bucket_id_to_path_mapping={};

def parse_args(argv):                                                           
    global file_all_vol_bucket_object_ids;                                      
    global file_files_in_a_line_name_parentID_objectId;                         
    global file_dirs_in_a_line_name_parentID_objectId;                          
    try:                                                                        
        opts, args = getopt.getopt(argv,"hb:f:d:",["bfile=","ffile=", "dfile="])
    except getopt.GetoptError:                                                  
        print ('test.py -b <bucketfiles> -f <filetable_file> -d <dirtable_file>')
        sys.exit(2)                                                             
    for opt, arg in opts:                                                       
        if opt == '-h':                                                         
            print ('test.py -b <bucketfiles> -f <filetable_file> -d <dirtable_file>')
            ys.exit()                                                           
        elif opt in ("-b", "--bfile"):                                          
            file_all_vol_bucket_object_ids = arg                                
        elif opt in ("-f", "--ffile"):                                          
            file_files_in_a_line_name_parentID_objectId = arg                   
        elif opt in ("-d", "--dfile"):                                          
            file_dirs_in_a_line_name_parentID_objectId = arg                    
    print ('first file is "', file_all_vol_bucket_object_ids)                   
    print ('second file is "', file_files_in_a_line_name_parentID_objectId)     
    print ('third file is "', file_dirs_in_a_line_name_parentID_objectId)       
                                                                           

def load_root_volumes_buckets():
    global file_all_vol_bucket_object_ids;
    global bucket_id_to_path_mapping;
    b_paths = open(file_all_vol_bucket_object_ids, "r");
    for line in b_paths:
        x=line.split(":");
        vol_name=x[0];
        bucket_name=x[1];
        bucket_object_id=x[2].split("\n")[0];
        bucket_id_to_path_mapping[bucket_object_id]="/"+vol_name+"/"+bucket_name;

def load_dir_table_and_file_table():
    global ft_mappings;
    global file_files_in_a_line_name_parentID_objectId;
    global file_dirs_in_a_line_name_parentID_objectId;
    map = open(file_files_in_a_line_name_parentID_objectId, "r");
    for line in map:
        x=line.split(":");
        name=x[0];
        parent=x[1];
        oid=x[2].split("\n")[0];
        ft_mappings[parent + "/" + oid]=name;
        all_child_to_parent[oid]=parent;
    map.close();
    map = open(file_dirs_in_a_line_name_parentID_objectId, "r");
    for line in map:
        x=line.split(":");
        name=x[0];
        parent=x[1];
        oid=x[2].split("\n")[0];
        ft_mappings[parent + "/" + oid]=name;
        all_child_to_parent[oid]=parent;


def using_ft_mappings_rebuild_all_files_from_json_tables():
    global ft_mappings, bucket_id_to_path_mapping;
    global all_child_to_parent;
    for parent_child_oid, child_name in ft_mappings.items():
        full_path= "";
        full_path_oids="";
        parent_oid=parent_child_oid.split("/")[0];
        child_oid=parent_child_oid.split("/")[1];
    
        while parent_oid != None:
            child_name = ft_mappings[parent_oid + "/" + child_oid];
            if full_path == "":
                full_path = child_name;
                full_path_oids = child_oid;
            else:
                full_path = child_name  + "/" + full_path;
                full_path_oids = child_oid + "/" + full_path_oids;
            child_oid=parent_oid;
            parent_oid=all_child_to_parent.get(child_oid, None); 
        root = bucket_id_to_path_mapping.get(child_oid, None);
        if root !=None:
            full_path = root + "/" + full_path; 
            print("rebuild_all_files_from_json_tables: Full Path:/" + full_path);
        else:
            print("Not Found during rebuild_all_files_from_json_tables: Full Path:/" + full_path +":" + full_path_oids);
        # Also print all the buckets
        for bucket in bucket_id_to_path_mapping.values():
            print("rebuild_all_files_from_json_tables: Full Path:/" + bucket);
        
    

def main():
    parse_args(sys.argv[1:])
    load_root_volumes_buckets();
    load_dir_table_and_file_table();
    using_ft_mappings_rebuild_all_files_from_json_tables();
    
main();
